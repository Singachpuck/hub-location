{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k4gSyrmCu9c7"
   },
   "source": [
    "# Some information on this notebook\n",
    "\n",
    "Google Colab provides an efficient environment for writing codes collaboratively with your **team mates**. \n",
    "\n",
    "For us **teachers**, this environment makes it possible to follow your work, whether we are all face-to-face at IMT Atlantique, in hybrid mode, or totally remote. \n",
    "\n",
    "This notebook offers you a **skeleton** of an ILS meta-heuristics, pre-configured for the use-case on the hub location problem. \n",
    "\n",
    "To collaborate with your team mates on this notebook, you should : \n",
    "\n",
    "- First **save a copy of this file in your Google Drive**: \n",
    "\n",
    "  Go to **File** / **Fichier**, then click on **Save a copy in Drive** / **Sauver une copie dans Google Drive**. \n",
    "\n",
    "- Then, **open that copy**, and **share that copy with your team mates** (and your teacher obviously): \n",
    "\n",
    "  Click on the top right on **Share** / **Partager**, then in the window **Obtenir le lien**, change the sharing method **Restricted** / **Limité** to **Anyone with the link** / **Tous les utilisateurs disposant du lien**, and change **Viewer** / **Lecteur** to **Editor** / **Editeur**. Finally click on **Copy link** / **Copier le lien**, and share this link with your team mates. \n",
    "\n",
    "The best is probably to put that link in the header of your Mattermost team, so that your teacher and your team mates can easily find it. \n",
    "\n",
    "**Before starting to code**, you should execute the first cell below, which helps you to upload the data files (in Excel format) to your notebook. You can also do this by hand, by: \n",
    "\n",
    "- Clicking on the left on the small **folder icon**, \n",
    "- Creating a **directory** for the data files (call it data), \n",
    "- **Uploading** the two Excel files provided in the website (the small and the large problem) in that directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQZiF7O9O2H3"
   },
   "source": [
    "\n",
    "# Upload of the data files (do only once !!)\n",
    "\n",
    "The cell below contains some code to\n",
    "\n",
    "- **Upload** the Excel files containing the **data** of the problems,\n",
    "- **Create** a **directory** for those files (we chose to call that directory `data` for some obvious reasons),\n",
    "- **Move** the data files to the `data` directory,\n",
    "- **Remove** the `sample_data` directory which is created by default when a new Google Colab notebook is created.\n",
    "\n",
    "Once executed at the beginning of your work, you can **comment this cell out** (by putting `#` in front of each line), so that it is not executed every time you execute the whole notebook ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "42FdYz9lKXAS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# uploaded = files.upload()\n",
    "# dest_path = \"/content/data/\"\n",
    "# os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "# shutil.move(\"/content/InputDataHubLargeInstance.xlsx\", dest_path)\n",
    "# shutil.move(\"/content/InputDataHubSmallInstance.xlsx\", dest_path)\n",
    "# shutil.rmtree(\"/content/sample_data/\", ignore_errors=True, onerror=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQvRgd4IJtTa"
   },
   "source": [
    "# Imports of modules\n",
    "\n",
    "Below we import some modules necessary to make this code work properly. \n",
    "\n",
    "You can add other modules here which you might need for your algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "9M3AxrugJOqT"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlhgCEc8J9-g"
   },
   "source": [
    "# Definitions of constants\n",
    "\n",
    "In the cell below we define some constants that we need in the meta-heuristic. \n",
    "\n",
    "The paths to the data files are also specified here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pUZEK9kzKJv3"
   },
   "outputs": [],
   "source": [
    "# ILS parameters\n",
    "\n",
    "ALPHA = 0.05\n",
    "MAX_ITER = 100     # maximum number of iterations (Stopping criterion of ILS)\n",
    "MAX_ITER_NI = 50   # number of iterations without improvement of the objective function (Stopping criterion of ILS)\n",
    "MAX_ITER_LS = 100  # maximum number of iterations of the local search operator (Outer loop)\n",
    "MAX_SWAPS = 1      # maximum number of swaps of the local search operator (Inner loop)\n",
    "NB_SWAPS = 1       # number of swaps in the perturbation operator\n",
    "\n",
    "# Path to data file\n",
    "\n",
    "INPUT_DATA = \"data/InputDataHubSmallInstance.xlsx\"  # Small instance\n",
    "#INPUT_DATA = \"/data/InputDataHubLargeInstance.xlsx\"  # Large instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0pQBRZywKzBE"
   },
   "source": [
    "# Functions to load and prepare the data\n",
    "\n",
    "In the cell below, you find two functions : \n",
    "\n",
    "- first, `read_excel_data`, which returns the values of a specific sheet in an Excel file,\n",
    "- then, `create_data_model` which fills the `data` dictionary with the data from the various sheets of the Excel file, as well as some dependent data, which is calculated from the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "IDT2OUseKOhz"
   },
   "outputs": [],
   "source": [
    "def read_excel_data(filename: str, sheet_name: str) -> np.ndarray:\n",
    "    \"\"\"Read data from an excel spreadsheet.\n",
    "\n",
    "    :param filename:\n",
    "    :param sheet_name:\n",
    "    :return: sheet data\n",
    "    \"\"\"\n",
    "    data = pd.read_excel(filename, sheet_name=sheet_name, header=None)\n",
    "    values = data.values\n",
    "    return values\n",
    "\n",
    "\n",
    "def create_data_model() -> dict:\n",
    "    \"\"\"Create the data model which gathers all problem parameters.\n",
    "\n",
    "    :return: data model structure\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    # This section contains all required data #\n",
    "    node_num = read_excel_data(INPUT_DATA, \"NodeNum\")\n",
    "    data['node_num'] = node_num[0][0]\n",
    "\n",
    "    # Flow between Nodes Read From Excel #\n",
    "    data['flow'] = read_excel_data(INPUT_DATA, \"flow(wij)\")\n",
    "\n",
    "    # Cost between Nodes Read from Excel #\n",
    "    data['var_cost'] = read_excel_data(INPUT_DATA, \"varCost(cij)\")\n",
    "\n",
    "    # Fixed Location Cost Read from Excel #\n",
    "    data['fix_cost'] = read_excel_data(INPUT_DATA, \"fixCost(fk)\")\n",
    "\n",
    "    # Discount Factor Read from Excel #\n",
    "    data['alpha'] = read_excel_data(INPUT_DATA, \"alpha\")\n",
    "\n",
    "    # Discount Factor Read from Excel #\n",
    "    data['cap'] = read_excel_data(INPUT_DATA, \"Cap(ckmax)\")\n",
    "\n",
    "    # Dependent Parameters\n",
    "    data['origin'] = data['flow'].sum(axis=1)\n",
    "    data['destination'] = data['flow'].sum(axis=0)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMNwG52HLi8V"
   },
   "source": [
    "# Functions to calculate the objective function from the solution representation\n",
    "\n",
    "The cell below contains 2 functions to calculate the objective function of an individual: \n",
    "- first `prufer_to_tree` which transforms the Prüfer representation of a solution into a tree,\n",
    "- second, `tree_to_prufer` which transforms a tree into a Prüfer representation,\n",
    "- third, `compute_of` which calculates the fitness (or objective function) of an individual (or a solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "h10apbZsLHST"
   },
   "outputs": [],
   "source": [
    "def prufer_to_tree(prufer_sequence: list) -> nx.Graph:\n",
    "    \"\"\"Transform the Prüfer representation into a tree.\n",
    "    \n",
    "    :param a: Prüfer sequence representing a tree\n",
    "    :return: tree as a graph structure\n",
    "    \"\"\"\n",
    "    return nx.from_prufer_sequence(prufer_sequence)\n",
    "\n",
    "\n",
    "def tree_to_prufer(tree: nx.Graph) -> list:\n",
    "    \"\"\"Transform a tree into a Prüfer sequence.\n",
    "\n",
    "    :param tree:\n",
    "    :return: Prüfer sequence representing the tree\n",
    "    \"\"\"\n",
    "    return nx.to_prufer_sequence(tree)\n",
    "\n",
    "\n",
    "def compute_of(individual: list, data: dict) -> float:\n",
    "    \"\"\"Calculate the objective function of the individual.\n",
    "    \n",
    "    :param individual: solution as a tree in Prüfer representation\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: value of the objective function for given individual\n",
    "\n",
    "    .. note:: this returns `inf` if the individual doesn't respect the constraints\n",
    "    \"\"\"\n",
    "    fitness = float(\"inf\")\n",
    "\n",
    "    graph = prufer_to_tree(individual)\n",
    "    tree_edges = list(graph.edges)\n",
    "    all_pairs_path = dict(nx.all_pairs_shortest_path(graph))\n",
    "\n",
    "    hubs = np.unique(individual)\n",
    "    fixed_cost = data['fix_cost'][hubs].sum()\n",
    "\n",
    "    variable_cost = 0\n",
    "    flow_to_hub = np.zeros(data['node_num'])\n",
    "    for i in range(data['node_num']):\n",
    "        for j in range(data['node_num']):\n",
    "            if j > i:\n",
    "                for x in range(len(all_pairs_path[i][j]) - 1):\n",
    "                    route = all_pairs_path[i][j]\n",
    "                    if route[x] in hubs and route[x + 1] in hubs:\n",
    "                        variable_cost = variable_cost + data['alpha'] * data['var_cost'][route[x], route[x + 1]] * (data['flow'][i, j] + data['flow'][j, i])\n",
    "                    else:\n",
    "                        variable_cost = variable_cost + data['var_cost'][route[x], route[x + 1]] * (data['flow'][i, j] + data['flow'][j, i])\n",
    "    fitness = fixed_cost + variable_cost[0]\n",
    "\n",
    "    # Calculating the Entering flow to Each Hub #\n",
    "    for i in range(len(tree_edges)):\n",
    "        if tree_edges[i][0] not in hubs:\n",
    "            flow_to_hub[tree_edges[i][1]] = flow_to_hub[tree_edges[i][1]] + (data['origin'][tree_edges[i][0]] + data['destination'][tree_edges[i][0]])\n",
    "        elif tree_edges[i][1] not in hubs:\n",
    "            flow_to_hub[tree_edges[i][0]] = flow_to_hub[tree_edges[i][0]] + (data['origin'][tree_edges[i][1]] + data['destination'][tree_edges[i][1]])\n",
    "    for i in range(len(hubs)):\n",
    "        flow_to_hub[hubs[i]] = flow_to_hub[hubs[i]] + (data['origin'][hubs[i]] + data['destination'][hubs[i]])\n",
    "\n",
    "    # Feasibility Check: Capacity Constraint #\n",
    "    exceed = np.subtract(data['cap'], flow_to_hub)\n",
    "    exceed_cap = exceed[hubs, hubs]\n",
    "    if min(exceed_cap) < 0:\n",
    "        fitness = float(\"inf\")\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ozSvLncMWrt"
   },
   "source": [
    "# Functions to create solutions or individuals\n",
    "\n",
    "The cell below contains two functions regarding individuals:\n",
    "\n",
    "- first, `generate_individual` to create a random individual, \n",
    "- second, `initial_solution` which returns this single randomly generated individual and its fitness."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iXE7bbbtrfPp"
   },
   "source": [
    "def generate_individual(nb_nodes: int) -> list:\n",
    "    \"\"\"Generate a random individual.\n",
    "\n",
    "    The created nodes will be labelled as integer from 0 to `nb_nodes`-1\n",
    "\n",
    "    :param nb_nodes: total number of nodes in an individual tree\n",
    "    :return: Prüfer representation of a random tree with given number of nodes\n",
    "    \"\"\"\n",
    "    individual = np.ndarray.tolist(np.random.randint(0, high=nb_nodes-1, size=nb_nodes-2, dtype='int'))\n",
    "    \n",
    "    return individual\n",
    "\n",
    "\n",
    "def initial_solution(data: dict) -> tuple:\n",
    "    \"\"\"Generate a random solution and calculate its fitness.\n",
    "    \n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: random solution in Prüfer representation, and its objective function value\n",
    "    \"\"\"\n",
    "    # here we are generating only one initial solution\n",
    "    of = float(\"inf\")\n",
    "    while of == float(\"inf\"):\n",
    "        solution = generate_individual(data['node_num'])\n",
    "        of = compute_of(solution, data)\n",
    "    return solution, of"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhReYN5zMoFR"
   },
   "source": [
    "# Functions for the local search\n",
    "\n",
    "Below you can find functions to perform a local search: \n",
    "- first the general high-level `local_search` function,\n",
    "- second the `reverse` function, which implements a swap operator, \n",
    "- third the `reverse_neighborhood` function which generates the neighborhood based on the reverse operator,\n",
    "- and finally the `unique_pairs` function, used by `swap_neighborhood`, wich generates unique pairs indexes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "7qPzoSOiNiFL"
   },
   "outputs": [],
   "source": [
    "def local_search(sol: list, of: float, data: dict) -> tuple:\n",
    "    \"\"\"Perform a local search.\n",
    "    \n",
    "    :param sol: input solution\n",
    "    :param of: objective function value of input solution\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: best neighbouring solution, and its objective function value\n",
    "    \"\"\"\n",
    "    # number of iterations local search\n",
    "    nb_iterations = 0\n",
    "\n",
    "    best_of = of\n",
    "    best_sol = sol\n",
    "\n",
    "    # Main loop local search\n",
    "    # Local search operators is repeated MAX_ITER_LS times\n",
    "    while nb_iterations <= MAX_ITER_LS:\n",
    "\n",
    "        nb_iterations += 1\n",
    "\n",
    "        # use an operator to perform local search\n",
    "\n",
    "        # ----> put your code here <----\n",
    "\n",
    "    return best_sol, best_of\n",
    "\n",
    "\n",
    "def reverse(p1: int, p2: int, parent: list) -> list:\n",
    "    \"\"\"Reverse operator.\n",
    "    \n",
    "    This function reverses the nodes between position `p1` and `p2` in the Prüfer sequence.\n",
    "\n",
    "    :param i: first position in `sol` sequence\n",
    "    :param j: second position in `sol` sequence\n",
    "    :param sol: parent solution to modify\n",
    "    :return: new solution \n",
    "    \"\"\"\n",
    "\n",
    "    # ----> put your code here <----\n",
    "\n",
    "    return parent[:p1] + reverse_part + parent[p2:]\n",
    "\n",
    "\n",
    "def reverse_neighborhood(sol: list, best_of: float, data: dict) -> tuple:\n",
    "    \"\"\"Neighborhood generation with a reversion operator.\n",
    "\n",
    "    All pairs of possible neighbours are investigated and create a solution and its objective function value each.\n",
    "    \n",
    "    :param sol: parent solution which neighbourhood to search\n",
    "    :param best_of: parent solution objective function value\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: list of neighbouring solutions, and corresponding list of neighbours objective function values\n",
    "    \"\"\"\n",
    "\n",
    "    # ----> put your code here <----\n",
    "\n",
    "    return n, of\n",
    "\n",
    "\n",
    "def unique_pairs(n: int):\n",
    "    \"\"\"Generator producing pairs of indexes in range(n).\n",
    "    \n",
    "    :param n:\n",
    "    :return: pair of indexes (generator)\n",
    "    \"\"\"\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            yield i, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gDKv178N0NO"
   },
   "source": [
    "# Functions for the perturbation of solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "6SxjOl1cNjR_"
   },
   "outputs": [],
   "source": [
    "def swap(i: int, j: int, sol: list) -> list:\n",
    "    \"\"\"Swap operator.\n",
    "    \n",
    "    This function simply swaps the nodes at position `i` and `j` in the Prüfer sequence.\n",
    "\n",
    "    :param i: first position in `sol` sequence\n",
    "    :param j: second position in `sol` sequence\n",
    "    :param sol: parent solution to modify\n",
    "    :return: new solution \n",
    "    \"\"\"\n",
    "\n",
    "    # ----> put your code here <----\n",
    "\n",
    "    return sol\n",
    "\n",
    "def random_swap(sol: list) -> list:\n",
    "    \"\"\"Random perturation.\n",
    "    \n",
    "    Applies `NB_SWAPS` random swap operations on the solution.\n",
    "\n",
    "    :param sol: parent solution\n",
    "    :return: modified solution\n",
    "    \"\"\"\n",
    "\n",
    "    # ----> put your code here <----\n",
    "\n",
    "    return sol\n",
    "\n",
    "# This function is the main body of the perturbation operator, wherein the random_swap function is called\n",
    "def perturb(sol: list, data: dict) -> tuple:\n",
    "    \"\"\"Add random perturbations on the solution.\n",
    "\n",
    "    :param sol: current solution to modify\n",
    "    :param data: data model including all parameters of the problem\n",
    "    :return: new solution, and its objective function value\n",
    "    \"\"\"\n",
    "\n",
    "    # ----> put your code here <----\n",
    "\n",
    "    return pert_sol, pert_of"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvKfEcCyN9V1"
   },
   "source": [
    "# Main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "0kCpz-PhObA_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random solution\n",
      "Initial objective function value: [8596005.15]\n",
      "Solution: [0, 5, 1, 2, 0, 5]\n",
      "\n",
      "Local Search\n",
      "Objective function value: [8596005.15]\n",
      "Tour: [0, 5, 1, 2, 0, 5]\n",
      "Graph with 8 nodes and 7 edges\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pert_sol' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[30], line 47\u001B[0m\n\u001B[0;32m     45\u001B[0m nb_iterations \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# ******************Perturbation**********************************\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m pert_sol, pert_of \u001B[38;5;241m=\u001B[39m \u001B[43mperturb\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbest_sol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# print(pert_of)\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# ******************Local Search***********************************\u001B[39;00m\n\u001B[0;32m     51\u001B[0m best_sol_pert, best_of_pert \u001B[38;5;241m=\u001B[39m local_search(pert_sol, pert_of, data)\n",
      "Cell \u001B[1;32mIn[29], line 40\u001B[0m, in \u001B[0;36mperturb\u001B[1;34m(sol, data)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Add random perturbations on the solution.\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \n\u001B[0;32m     33\u001B[0m \u001B[38;5;124;03m:param sol: current solution to modify\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;124;03m:param data: data model including all parameters of the problem\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;124;03m:return: new solution, and its objective function value\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# ----> put your code here <----\u001B[39;00m\n\u001B[1;32m---> 40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpert_sol\u001B[49m, pert_of\n",
      "\u001B[1;31mNameError\u001B[0m: name 'pert_sol' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # *************************Initialisation***************************\n",
    "    # initialise the data\n",
    "    data = create_data_model()\n",
    "\n",
    "    # init number of iterations\n",
    "    nb_iterations = 0\n",
    "\n",
    "    # find initial solution (just one) with a constructive heuristic\n",
    "    best_sol, best_of = initial_solution(data)\n",
    "\n",
    "    # ********************************************************************\n",
    "\n",
    "    print(\"Random solution\")\n",
    "    print(\"Initial objective function value:\", best_of)\n",
    "    print(\"Solution:\", best_sol)\n",
    "\n",
    "    # **************************Local Search******************************\n",
    "\n",
    "    best_sol, best_of = local_search(best_sol, best_of, data)\n",
    "    best_known = best_sol\n",
    "    best_of_known = best_of\n",
    "\n",
    "    print(\"\\nLocal Search\")\n",
    "    print(\"Objective function value:\", best_of)\n",
    "    print(\"Tour:\", best_sol)\n",
    "\n",
    "    best_solution = prufer_to_tree(best_sol)\n",
    "\n",
    "    print(best_solution)\n",
    "\n",
    "    # graph = nx.Graph(best_solution)\n",
    "    # plt.figure(2)\n",
    "    # nx.draw(graph, with_labels=True)\n",
    "    # plt.show()\n",
    "\n",
    "    # ********************************************************************\n",
    "\n",
    "    # ******************************ILS***********************************\n",
    "    flag_continue = True\n",
    "    improve = 0\n",
    "\n",
    "    while flag_continue and nb_iterations <= MAX_ITER and improve <= MAX_ITER_NI:\n",
    "\n",
    "        nb_iterations += 1\n",
    "        # ******************Perturbation**********************************\n",
    "        pert_sol, pert_of = perturb(best_sol, data)\n",
    "        # print(pert_of)\n",
    "\n",
    "        # ******************Local Search***********************************\n",
    "        best_sol_pert, best_of_pert = local_search(pert_sol, pert_of, data)\n",
    "        # print(best_of_pert)\n",
    "\n",
    "        # ******************Aceptance criterion***************************\n",
    "        if best_of_pert < best_of_known:\n",
    "            best_known = best_sol_pert\n",
    "            best_of_known = best_of_pert\n",
    "            improve = 0\n",
    "        else:\n",
    "            improve += 1\n",
    "\n",
    "        if best_of_pert < best_of * (1 + ALPHA):\n",
    "            best_of = best_of_pert\n",
    "            best_sol = best_sol_pert\n",
    "        else:\n",
    "            flag_continue = False\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"After\", nb_iterations, \" ILS iterations, the best solution is:\")\n",
    "    print(best_known)\n",
    "    print(\"with total cost:\", best_of_known)\n",
    "\n",
    "    best_solution = prufer_to_tree(best_known)\n",
    "\n",
    "    graph = nx.Graph(best_solution)\n",
    "    plt.figure(2)\n",
    "    nx.draw(graph, with_labels=True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
